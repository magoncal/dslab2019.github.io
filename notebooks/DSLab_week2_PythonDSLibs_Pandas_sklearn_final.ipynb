{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSLab_week2_PythonDSLibs-Pandas_sklearn-final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "8FypPjfp6dZ3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting familiar with Pandas"
      ]
    },
    {
      "metadata": {
        "id": "wd_yumkj6daC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Pandas \n",
        "# there are several ways to change a column in a dataframe\n",
        "# A short intro to pandas https://pandas.pydata.org/pandas-docs/stable/10min.html\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import timeit"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oxnPOPPO6daZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First step: make the dataframe\n",
        "dates = pd.date_range('20130101', '20140101') #366\n",
        "data = pd.DataFrame(np.random.randn(366,4), index=dates, columns=list('ABCD'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3Zozsa46daq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.1: Inspect the dataframe with the following commands: head(), tail(), describe."
      ]
    },
    {
      "metadata": {
        "id": "QsQR2znM6dat",
        "colab_type": "code",
        "outputId": "5a279e97-1f46-4793-c407-87d277442e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>-0.865065</td>\n",
              "      <td>-1.323184</td>\n",
              "      <td>-2.060583</td>\n",
              "      <td>-1.093683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>-1.434577</td>\n",
              "      <td>2.695614</td>\n",
              "      <td>0.982652</td>\n",
              "      <td>0.769584</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>-1.520955</td>\n",
              "      <td>-0.184620</td>\n",
              "      <td>1.768990</td>\n",
              "      <td>0.251867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>0.155172</td>\n",
              "      <td>-0.126022</td>\n",
              "      <td>-0.095785</td>\n",
              "      <td>-0.602780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>-0.584360</td>\n",
              "      <td>0.568325</td>\n",
              "      <td>-1.016321</td>\n",
              "      <td>0.447643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A         B         C         D\n",
              "2013-01-01 -0.865065 -1.323184 -2.060583 -1.093683\n",
              "2013-01-02 -1.434577  2.695614  0.982652  0.769584\n",
              "2013-01-03 -1.520955 -0.184620  1.768990  0.251867\n",
              "2013-01-04  0.155172 -0.126022 -0.095785 -0.602780\n",
              "2013-01-05 -0.584360  0.568325 -1.016321  0.447643"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "RzlSsC_G6dbK",
        "colab_type": "code",
        "outputId": "ff251a91-d788-4366-cb46-6769e93e12bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-12-28</th>\n",
              "      <td>0.397898</td>\n",
              "      <td>0.354023</td>\n",
              "      <td>0.787082</td>\n",
              "      <td>-0.091770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-29</th>\n",
              "      <td>0.888595</td>\n",
              "      <td>-0.437082</td>\n",
              "      <td>-0.570970</td>\n",
              "      <td>0.515705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-30</th>\n",
              "      <td>-0.246886</td>\n",
              "      <td>0.575863</td>\n",
              "      <td>0.236348</td>\n",
              "      <td>0.606172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-12-31</th>\n",
              "      <td>-0.740922</td>\n",
              "      <td>-1.787007</td>\n",
              "      <td>-0.068582</td>\n",
              "      <td>0.804153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014-01-01</th>\n",
              "      <td>-0.906857</td>\n",
              "      <td>0.956664</td>\n",
              "      <td>2.227654</td>\n",
              "      <td>1.137369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A         B         C         D\n",
              "2013-12-28  0.397898  0.354023  0.787082 -0.091770\n",
              "2013-12-29  0.888595 -0.437082 -0.570970  0.515705\n",
              "2013-12-30 -0.246886  0.575863  0.236348  0.606172\n",
              "2013-12-31 -0.740922 -1.787007 -0.068582  0.804153\n",
              "2014-01-01 -0.906857  0.956664  2.227654  1.137369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "JmBYrxYg6dbc",
        "colab_type": "code",
        "outputId": "ae3ef46c-7628-411b-e112-96f9ca4a324d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>366.000000</td>\n",
              "      <td>366.000000</td>\n",
              "      <td>366.000000</td>\n",
              "      <td>366.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.038648</td>\n",
              "      <td>-0.068622</td>\n",
              "      <td>-0.033503</td>\n",
              "      <td>-0.111356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.939546</td>\n",
              "      <td>0.994116</td>\n",
              "      <td>0.974423</td>\n",
              "      <td>1.020539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.252458</td>\n",
              "      <td>-3.182307</td>\n",
              "      <td>-2.967590</td>\n",
              "      <td>-2.828728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.607056</td>\n",
              "      <td>-0.777271</td>\n",
              "      <td>-0.650711</td>\n",
              "      <td>-0.824148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.014083</td>\n",
              "      <td>-0.147942</td>\n",
              "      <td>-0.065393</td>\n",
              "      <td>-0.167854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.591228</td>\n",
              "      <td>0.589572</td>\n",
              "      <td>0.603573</td>\n",
              "      <td>0.584311</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.014765</td>\n",
              "      <td>2.761000</td>\n",
              "      <td>2.798826</td>\n",
              "      <td>2.784084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                A           B           C           D\n",
              "count  366.000000  366.000000  366.000000  366.000000\n",
              "mean    -0.038648   -0.068622   -0.033503   -0.111356\n",
              "std      0.939546    0.994116    0.974423    1.020539\n",
              "min     -3.252458   -3.182307   -2.967590   -2.828728\n",
              "25%     -0.607056   -0.777271   -0.650711   -0.824148\n",
              "50%     -0.014083   -0.147942   -0.065393   -0.167854\n",
              "75%      0.591228    0.589572    0.603573    0.584311\n",
              "max      3.014765    2.761000    2.798826    2.784084"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "hmD-7Yob6dbp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.2:  The index is a time series, and pandas has a build-in command for re-sampling dataframes (documentation: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.resample.html).  Use resample to get the median every 2 days and save this as a new dataframe."
      ]
    },
    {
      "metadata": {
        "id": "5wJqmywT6dbs",
        "colab_type": "code",
        "outputId": "a4df7617-a829-45d8-b5c0-e4a48cd723e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "cell_type": "code",
      "source": [
        "#Solution: \n",
        "data2 = data.resample('2D').median()\n",
        "data2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>-1.149821</td>\n",
              "      <td>0.686215</td>\n",
              "      <td>-0.538965</td>\n",
              "      <td>-0.162050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>-0.682891</td>\n",
              "      <td>-0.155321</td>\n",
              "      <td>0.836603</td>\n",
              "      <td>-0.175456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>-0.067507</td>\n",
              "      <td>-0.139621</td>\n",
              "      <td>-0.851468</td>\n",
              "      <td>-0.502497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-07</th>\n",
              "      <td>-0.461183</td>\n",
              "      <td>0.974751</td>\n",
              "      <td>-0.855159</td>\n",
              "      <td>0.132310</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-09</th>\n",
              "      <td>0.396234</td>\n",
              "      <td>-1.100027</td>\n",
              "      <td>-0.975390</td>\n",
              "      <td>0.602435</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A         B         C         D\n",
              "2013-01-01 -1.149821  0.686215 -0.538965 -0.162050\n",
              "2013-01-03 -0.682891 -0.155321  0.836603 -0.175456\n",
              "2013-01-05 -0.067507 -0.139621 -0.851468 -0.502497\n",
              "2013-01-07 -0.461183  0.974751 -0.855159  0.132310\n",
              "2013-01-09  0.396234 -1.100027 -0.975390  0.602435"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "HXLwRIzL6db2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.3: Inspect the new dataframe to see the difference in size compared to the inital dataframe."
      ]
    },
    {
      "metadata": {
        "id": "WIhom0Ar6db9",
        "colab_type": "code",
        "outputId": "e4b150b5-07e3-4f1c-a625-d1980ec15944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Solution: \n",
        "print(data.shape)\n",
        "print(data2.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(366, 4)\n",
            "(183, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p5JU3mAs6dcQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.4:  Write your new dataframe to a csv file."
      ]
    },
    {
      "metadata": {
        "id": "CnSrCVLm6dcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Solution: \n",
        "data2.to_csv(\"data2.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gmovSgWc6dcd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.5: Merge the two dataframes. There are several ways to do this, see also https://pandas.pydata.org/pandas-docs/stable/merging.html."
      ]
    },
    {
      "metadata": {
        "id": "fM8zM2ZK6dcf",
        "colab_type": "code",
        "outputId": "e686007d-6cde-4afc-e158-04e9a233bb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "merged = pd.concat([data, data2])\n",
        "merged.index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatetimeIndex(['2013-01-01', '2013-01-02', '2013-01-03', '2013-01-04',\n",
              "               '2013-01-05', '2013-01-06', '2013-01-07', '2013-01-08',\n",
              "               '2013-01-09', '2013-01-10',\n",
              "               ...\n",
              "               '2013-12-13', '2013-12-15', '2013-12-17', '2013-12-19',\n",
              "               '2013-12-21', '2013-12-23', '2013-12-25', '2013-12-27',\n",
              "               '2013-12-29', '2013-12-31'],\n",
              "              dtype='datetime64[ns]', length=549, freq=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "0iDecmEz6dco",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 1.6: There are several ways to perform actions on the dataframe columns. The dataframe has several columns containing negative values. For this exercise, find these negative values on a column, and create a new column with their absolute value, using a list comprehension, and after this, using a lambda function. You can use the magic timeit to see if there is a difference between these operations."
      ]
    },
    {
      "metadata": {
        "id": "IzGhRf0y6dcs",
        "colab_type": "code",
        "outputId": "6b645fb6-0f37-4fb2-e1ca-bd4605dde84e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "# method 1: list comprehension\n",
        "start = timeit.timeit()\n",
        "\n",
        "a = [np.abs(x) for x in data.B]\n",
        "data[\"abs(B)\"] = pd.Series(a,index=data.index)\n",
        "end = timeit.timeit()\n",
        "print(end - start)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.004830483999995749\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>abs(B)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>-0.865065</td>\n",
              "      <td>-1.323184</td>\n",
              "      <td>-2.060583</td>\n",
              "      <td>-1.093683</td>\n",
              "      <td>1.323184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>-1.434577</td>\n",
              "      <td>2.695614</td>\n",
              "      <td>0.982652</td>\n",
              "      <td>0.769584</td>\n",
              "      <td>2.695614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>-1.520955</td>\n",
              "      <td>-0.184620</td>\n",
              "      <td>1.768990</td>\n",
              "      <td>0.251867</td>\n",
              "      <td>0.184620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>0.155172</td>\n",
              "      <td>-0.126022</td>\n",
              "      <td>-0.095785</td>\n",
              "      <td>-0.602780</td>\n",
              "      <td>0.126022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>-0.584360</td>\n",
              "      <td>0.568325</td>\n",
              "      <td>-1.016321</td>\n",
              "      <td>0.447643</td>\n",
              "      <td>0.568325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A         B         C         D    abs(B)\n",
              "2013-01-01 -0.865065 -1.323184 -2.060583 -1.093683  1.323184\n",
              "2013-01-02 -1.434577  2.695614  0.982652  0.769584  2.695614\n",
              "2013-01-03 -1.520955 -0.184620  1.768990  0.251867  0.184620\n",
              "2013-01-04  0.155172 -0.126022 -0.095785 -0.602780  0.126022\n",
              "2013-01-05 -0.584360  0.568325 -1.016321  0.447643  0.568325"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "6THTnwUd6dc0",
        "colab_type": "code",
        "outputId": "84c8df5c-d839-448b-cbb2-03b7164a997e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "# method 2: lambda function\n",
        "start = timeit.timeit()\n",
        "\n",
        "data[\"abs(C)\"] = data.C.apply(lambda x: np.abs(x))\n",
        "end = timeit.timeit()\n",
        "print(end - start)\n",
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.006581885999963788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "      <th>B</th>\n",
              "      <th>C</th>\n",
              "      <th>D</th>\n",
              "      <th>abs(B)</th>\n",
              "      <th>abs(C)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2013-01-01</th>\n",
              "      <td>-0.865065</td>\n",
              "      <td>-1.323184</td>\n",
              "      <td>-2.060583</td>\n",
              "      <td>-1.093683</td>\n",
              "      <td>1.323184</td>\n",
              "      <td>2.060583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-02</th>\n",
              "      <td>-1.434577</td>\n",
              "      <td>2.695614</td>\n",
              "      <td>0.982652</td>\n",
              "      <td>0.769584</td>\n",
              "      <td>2.695614</td>\n",
              "      <td>0.982652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-03</th>\n",
              "      <td>-1.520955</td>\n",
              "      <td>-0.184620</td>\n",
              "      <td>1.768990</td>\n",
              "      <td>0.251867</td>\n",
              "      <td>0.184620</td>\n",
              "      <td>1.768990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-04</th>\n",
              "      <td>0.155172</td>\n",
              "      <td>-0.126022</td>\n",
              "      <td>-0.095785</td>\n",
              "      <td>-0.602780</td>\n",
              "      <td>0.126022</td>\n",
              "      <td>0.095785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013-01-05</th>\n",
              "      <td>-0.584360</td>\n",
              "      <td>0.568325</td>\n",
              "      <td>-1.016321</td>\n",
              "      <td>0.447643</td>\n",
              "      <td>0.568325</td>\n",
              "      <td>1.016321</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   A         B         C         D    abs(B)    abs(C)\n",
              "2013-01-01 -0.865065 -1.323184 -2.060583 -1.093683  1.323184  2.060583\n",
              "2013-01-02 -1.434577  2.695614  0.982652  0.769584  2.695614  0.982652\n",
              "2013-01-03 -1.520955 -0.184620  1.768990  0.251867  0.184620  1.768990\n",
              "2013-01-04  0.155172 -0.126022 -0.095785 -0.602780  0.126022  0.095785\n",
              "2013-01-05 -0.584360  0.568325 -1.016321  0.447643  0.568325  1.016321"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Ldrd1OoP6dc-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Supervised learning using scikit-learn - Classification of MNIST data"
      ]
    },
    {
      "metadata": {
        "id": "KgzFlUTz6ddA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.1: Download the digit ('MNIST original') dataset from  mldata.org, which is a public repository for machine learning data. Divide the data into training and testing. Please use 1/7 for training and the rest for testing. \n",
        "\n",
        "Hint: The sklearn.datasets package is able to directly download data sets from the repository using the function sklearn.datasets.fetch_mldata. Generate the training and testing set by importing train_test_split from sklearn.model_selection\n",
        "\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "IxFvwjRL6ddE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "import sklearn \n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "# Download the MNIST original dataset\n",
        "# Load data from https://www.openml.org/d/554\n",
        "x, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the images into training and testing\n",
        "x_tr, x_va, y_tr, y_va = train_test_split(x, y, test_size = 1/7.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "C20G7FRr6ddI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.2: The optimal performance of many machine learning algorithms is affected by scale. Typically, you need to scale the features in your data before applying any algorithm. Normalize the data and plot some random images from the dataset.  \n",
        "\n",
        "Hint: Use StandardScaler from sklearn.preprocessing to help you standardize the dataset’s features onto unit scale (mean = 0 and variance = 1)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "OhdXffeB6ddO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit on training set only\n",
        "scaler.fit(x_tr)\n",
        "\n",
        "# Apply transform to both the training set and the test set\n",
        "x_tr = scaler.transform(x_tr)\n",
        "x_va = scaler.transform(x_va)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_N4fOReI6ddY",
        "colab_type": "code",
        "outputId": "f0ba5e03-0a77-48d4-f5ab-2267cfc0d149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution (Visualization)\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(x_tr[0].reshape((28,28)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fe447d76898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niYASXSQCSnSRCPwfXt2CCqUnIBwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "6tXdUmGD6ddm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.3: Logistic regression is one of the simplest linear classification algorithms. Fit a logistic regression model to the training images. Compute the accuracy of the classifier on the test images, and the time needed to train the model.¶\n",
        "\n",
        "Hint: Use LogisticRegression from sklearn.linear_model. To increase speed, change the default solver to 'lbfgs'\n"
      ]
    },
    {
      "metadata": {
        "id": "EJTqEnUi6ddp",
        "colab_type": "code",
        "outputId": "84480a2e-669b-4dde-bd05-f608289896da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "from time import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "tic = time()\n",
        "# Fit a linear regression model\n",
        "lr = LogisticRegression(solver='lbfgs',verbose=1,n_jobs=-1)\n",
        "lr.fit(x_tr, y_tr)\n",
        "\n",
        "# Compute the classification score\n",
        "print(lr.score(x_tr, y_tr))\n",
        "print(lr.score(x_va, y_va))\n",
        "toc = time()\n",
        "print('The total time is %s seconds ' % (toc-tic))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  4.3min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.9321833333333334\n",
            "0.9158\n",
            "The total time is 260.70635056495667 seconds \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RVCrmKMv6ddx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a5T2GIiW6dd6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.4: Apply Principle Component Analysis (PCA) to the training signals by keeping only (a) 25%, (b) 75%, and (c) 95% of the energy. For each of the three cases, output the number of the required principle components.Then, plot the Cumulative Explained Variance over PCA. Finally, choose a random image from the dataset, and show its approximation with the PCA components. \n",
        "\n",
        "Hint: For computing the Cumulative Explained Variance over PCA use:\n",
        "```\n",
        "pca.explained_variance_ratio_.cumsum()\n",
        "\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "bs8WV4xK6dd7",
        "colab_type": "code",
        "outputId": "7c204a5d-0790-4c52-f5d4-f6c8c3e99a0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Fit a PCA model\n",
        "print(\"Fitting PCA 25%\")\n",
        "pca25 = PCA(n_components=0.25)\n",
        "pca25.fit(x_tr)\n",
        "print(\"Finished fitting PCA 25%\")\n",
        "\n",
        "print(\"Fitting PCA 75%\")\n",
        "pca75 = PCA(n_components=0.75)\n",
        "pca75.fit(x_tr)\n",
        "print(\"Finished fitting PCA 75%\")\n",
        "\n",
        "print(\"Fitting PCA 95%\")\n",
        "pca95 = PCA(n_components=0.95)\n",
        "pca95.fit(x_tr)\n",
        "print(\"Finished fitting PCA 95%\\n\\n\")\n",
        "\n",
        "\n",
        "# Compute the number of PCA components\n",
        "print(\"Number of components for 25% is: \" + str(pca25.n_components_))\n",
        "print(\"Number of components for 75% is: \" + str(pca75.n_components_))\n",
        "print(\"Number of components for 95% is: \" + str(pca95.n_components_))\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting PCA 25%\n",
            "Finished fitting PCA 25%\n",
            "Fitting PCA 75%\n",
            "Finished fitting PCA 75%\n",
            "Fitting PCA 95%\n",
            "Finished fitting PCA 95%\n",
            "\n",
            "\n",
            "Number of components for 25% is: 9\n",
            "Number of components for 75% is: 120\n",
            "Number of components for 95% is: 329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Yqdu2I146deC",
        "colab_type": "code",
        "outputId": "5e974044-a756-4cb4-d664-f4c2cb0198ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "# Plot the Cumulative Explained Variance over PCA\n",
        "cev25 = pca25.explained_variance_ratio_.sum()\n",
        "cev75 = pca75.explained_variance_ratio_.sum()\n",
        "cev95 = pca95.explained_variance_ratio_.sum()\n",
        "\n",
        "print(\"The Cumulative Explained Variance of the 25% PCA model is: \" + str(cev25))\n",
        "print(\"The Cumulative Explained Variance of the 75% PCA model is: \" + str(cev75))\n",
        "print(\"The Cumulative Explained Variance of the 95% PCA model is: \" + str(cev95))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Cumulative Explained Variance of the 25% PCA model is: 0.26420783426145883\n",
            "The Cumulative Explained Variance of the 75% PCA model is: 0.7505683303267402\n",
            "The Cumulative Explained Variance of the 95% PCA model is: 0.9501584530941278\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PoXh4_3m6deI",
        "colab_type": "code",
        "outputId": "f51b9773-3fa0-4c82-9143-10a62e4cd45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "# Choose a random image from the dataset, and show its approximation with the PCA components\n",
        "random_image = x[np.random.randint(0, x.shape[0], 1)]\n",
        "plt.figure(figsize=(8,4));\n",
        "\n",
        "# Original Image\n",
        "plt.subplot(1, 2, 1);\n",
        "plt.imshow(random_image.reshape(28,28))\n",
        "\n",
        "# Approximation\n",
        "plt.subplot(1, 2, 2);\n",
        "transformed_image = pca25.inverse_transform(pca25.transform(random_image))\n",
        "print(transformed_image.shape)\n",
        "plt.imshow(transformed_image[0].reshape(28,28))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f98582f22e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAADqCAYAAADjwE/yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHsxJREFUeJzt3X2QHVWd//HPEBIIkycmAZIMMUQM\nB2OEgoRyszBDZN2FFQEpoHhIUZRQtaBkwcItgY1FRbSWBUrZAvEBUYI8GKQiGBAoVndlsFYlFSIu\nCIcgW4AkIU/kaQJ5Ir8/Mvf+enr6fPvenntP35D3659093fO7XN77plvum9/+7Tt3r1bAAAgnv3K\n7gAAAPsaki8AAJGRfAEAiIzkCwBAZCRfAAAiI/kCABDZ/kUbOuduk/Q3knZLutp7v8T4ceqZgNq0\nlbHTesZzT09Pv/E8Y8YMLV26tMk9rN3e3J+2tvCv34rV47jjjtOyZcuq6x988EFDXreoVvt9SY3r\nU3d3d/CXVujM1zl3sqSp3vtZki6TdHvBvgEo2WDHc3t7e1P6VRT9sdGffDH6VPSy899JelSSvPcv\nSzrYOTeqYb0CEBPjGYisaPIdL2lNYn1N3zYAex/GMxBZ4e98U0r5ngpAU5jjecaMGQMuy3V3dze1\nQ/WiP7aTTjqp7C7002rHR2p+n4om3xXq/z/jiZJWDr47AEpQ13hO34jS3d2tnp6e5vSsgL25PzFu\nuDrppJP029/+trpe9g1Xrfb7khrXJyuBF73s/LSkcyXJOXe8pBXe+80FXwtAuRjPQGSFzny99//j\nnFvqnPsfSR9IurKx3QIQy4d5POedLVrx/fYLn5tYsazXPOCAA8x+1MKagS7vfabb7r9/bX/6rX3m\nzYhXz4x5Q4YMKdSunn222gx+hb/z9d5f18iOACgP4xmIiydcAQAQGckXAIDISL4AAERG8gUAIDKS\nLwAAkTXqCVcAMChWuUyzykSKlhPVG0uW0lisB15Yx2DXrl11ve7OnTtrel3LYMq40rHk+mAeJlL0\nvWS1q/wem/UQEs58AQCIjOQLAEBkJF8AACIj+QIAEBnJFwCAyEi+AABERvIFACAy6nwB7NWyalwr\n2/LqPnfs2BGMNbLmdu3atdXlZI1tmhXbtm1bMJZXi5ru75tvvlldtmqWDzzwwGAsb5rEYcOGBWPp\nKQ2TvwdrusO8GmDrvdRbA1zZV73TNdaKM18AACIj+QIAEBnJFwCAyEi+AABERvIFACAyki8AAJFR\narQXeP/994OxZ555Jhj7yU9+Eoz99Kc/NfeZvn1+9+7dNd96H3LppZea8bvvvrvQ6+LDwZoWzyqz\n6e3tHbDt3XfflSRt3rzZ3OeWLVsKxbL2GWp32mmn6emnn66prTXWt2/fHozlSU5peNFFF+mJJ56o\nrlvlRB0dHcHYuHHjzH1a8bFjx/Zb37BhQ3W5vb092M4qX5LsqRuL/t2yypckSo0AANhrkHwBAIiM\n5AsAQGQkXwAAIiP5AgAQGckXAIDICpUaOedmS3pY0kt9m/7Xe//PjerUvubVV18dsO2oo46qbr/4\n4ouDbZcsWdKUPo0cOTK47fTTTw+2e+ihh4KxvPKma665JhibNm2a2RbFtcp4tspsKqVDWdavXz9g\n28qVK4OxvLa17HPdunXB2KpVqwZse/bZZ6vLa9asCbZNltykbd26NRjLky7RefTRR6vLY8aMCbY7\n/PDDg7EpU6aY+5w0aVLNr/vGG29UlydMmBBsly5RSrNmRLLKkKzXskrgBmMwdb7PeO/PbVhPAJSJ\n8QxExGVnAAAiG8yZ7zTn3GJJHZK+7r3/zwb1CUB8jGcgorYij8ZyznVKOknSzyR9VNJ/S/qY9z70\n/LNiz98C9j3FnoE3CPWO597e3t3WIwABVAXHc6Hkm+ace07S+d77/wv8CMnX0Io3XI0YMaLf+qZN\nmzRq1ChJxW+4Gj58uLlP673sQzdcRU++aXnjuaenp9947u7uVk9Pz6D3a91QVM8NV1deeaXuvPPO\nzFhe21r3Wc8NV0uWLNEJJ5xQXS/7hqstW7b0G99l33B11VVX6fbbb6+uD+aGK+s51fXccPWpT31K\nf/jDHyTl33Bl5dATTzwxOJ4LfefrnJvjnPuXvuXxkg6T9HaR1wJQLsYzEF/R73wXS3rQOXeWpGGS\nvmhccoak3//+98FYd3f3gG3bt2/X9OnTJUk7d+4MtrX+1zpv3rxg7IorrgjGJOmAAw4YsK1ylmD9\nD/LjH/94MDZ//nxznwsXLgzGbrzxRrMtBiXKeM67ymbN2mPNBJQ1c1Fl26ZNm8x9WvGNGzcGY/WW\nPiW3WWe31ixMH3zwQTA2dOjQYEwaWGqUXLdm7bHOtq33IQ28epZUuYpWkfw9HHzwwcF2eTMMWcfB\n+ruVdWxrPVMuWopUKPl67zdLOqPQHgG0FMYzEB+lRgAAREbyBQAgMpIvAACRkXwBAIiM5AsAQGQk\nXwAAIhvMs51Rh7vuuisYmzp1qrn9ueeeC7ZN1+8l5dX+1cuarqvCqu3L09XVVbgtWoNVy9uIp+ll\nyfpcVrZZTzySBtabJll1ntbT2rJe0zlXXbZqhC1W/eshhxxitk33ac6cOTXtc9u2bcFY3u/T+luQ\n/r0k161Hl+Y9Jc/aZ1tb+OFxWc9SqPTJOgZS8TpfznwBAIiM5AsAQGQkXwAAIiP5AgAQGckXAIDI\nSL4AAERGqVEkt912WzAWmtbsqaeekmTfel+G9957Lxj79re/HYxlTVOYNG3atMJ9QmuwyjnyWKVs\nVglJ1jRzHR0due0ke5o+a4pDq/wka/rDmTNnVpd37NgRbGuN9YkTJwZjkydPDsakgSU6F154YXXZ\nGs9vvfVWMLZq1Spzn9ZUqOnSp+T66NGjg+0OOuggc5/W3xjrs5kVq5RqWu9jMDjzBQAgMpIvAACR\nkXwBAIiM5AsAQGQkXwAAIiP5AgAQGaVGkVi3z4dikyZNalZ3cqXLIYYOHVrd9uUvfznYbsWKFcHY\nhAkTzH12dnbW0UOUJasso7LNmukmrwzJmoHImmEoa7afymcpbyYuK27NVrNly5ZgbOPGjQO2JWcu\ns8qbRo4cGYxZ42fcuHHBmDRwhrNk2dKGDRuC7bZu3RqMWSVKkl2OZc1qZM3Glvf7tD4nReXN3pRV\n6lYLznwBAIiM5AsAQGQkXwAAIiP5AgAQGckXAIDISL4AAERGqdE+yppZRZIWLVrUb/2CCy6obvvh\nD38YbGfNKvLAAw/U0UPsjYqWXUjSsGHDgjFrNpusz9yhhx4ajCVZ/X3//feDMaukJavEJllKs3nz\n5mBbq3zHKm+yyrSkge8zWQ6VVRpVkTVDU0Ve6Zj1+0yXDCXXrVIsq/wrr60la+aiyra818wrRQqp\nKfk656ZL+oWk27z333HOTZJ0n6QhklZKuth7Hy7qAtASGMtAa8j9b6pzrl3SHZJ+ndh8o6Q7vfdd\nkl6TdGlzugegURjLQOuo5RrRNkmflZR8dNFsSYv7lh+T9JnGdgtAEzCWgRbRVuv1aufcfElr+y5V\nrfbeH9q3/UhJ93nv/9ZoXuyiOLDvsb9Ia4BBjmX19vbubm9vb3Y3gQ+D4HhuxA1XTf9jgcYrcsPV\nwoULJUkXXXRRsJ11g8uTTz5p7nP27NlmHE1X01h+/vnn+613dXXp2Wef3fMCOTfhFGU90zf9mTvu\nuOO0bNmyzFha0RuurJuUVq9e3W/9vPPO08MPP1xdt264svpbuYksS96znZPv89hjj9ULL7xQXbee\n7bxy5cpgzGon2TcqjRkzprp80UUX6cEHH6yuJ587nZb3Pov+pzD9DOtPfOITeumllyTZnwNJ2r59\nezA2a9asYKzorYlbnHPD+5Y71f8yFoC9B2MZKEHR5PsrSef0LZ8j6anGdAdAZIxloAS5l52dczMk\nfUvSEZJ2OOfOlTRH0gLn3OWS3pB0bzM7ua/btGlTMPaDH/wgGLMuC91///3mPt96661+6xdccIF5\nubnisMMOC8a4rFyuRo1la0pB6zJu3iVpq+3w4cODsREjRgzYVpmmM++ys3Vp1IpZX9ukLzunt1mX\ncq1LnMlLtWlTpkwJxqT+x+HYY4/V8uXLq+vW3xdrWsC836c1NWC6Xje5bh3brHrcpKI1t1n1w5Vt\nefssWlucm3y990u1547ItL8vtEcApWAsA62Dx0sCABAZyRcAgMhIvgAAREbyBQAgMpIvAACRMaXg\nXsCaiu/aa6+N2JN8K1aEn9Fw6aX2M/u///3vB2PW9GSIK6uco5YSj7zpBq3fsVVqlDXdYGWbVe4i\n2U8nskpM1q5dG4y9+eab5rbXX3892HbdunXBmPXkpzzp4/fGG29Ul63SHuvJYnnTGNZTgpMssbKm\nVcx7Tav8yfr8Ff1MDwZnvgAAREbyBQAgMpIvAACRkXwBAIiM5AsAQGQkXwAAIqPUaC9w2mmnBWNz\n5swJxt59991g7OKLLzb3ecoppwzY9s4770iSXnnllUL9WbBggblPq+ThvvvuM9siHmtWo8GUZwwZ\nMiQYs0qGskqUKtus15SKz6CzZcuWYKy3t9fctnnz5mBbq/Qpq6SqIm/2pvQxSq4XPQYbN24095k1\nU1BFukwp+beqvb092M7qq2SXGlmfhaySqsq2vNmb8uIhnPkCABAZyRcAgMhIvgAAREbyBQAgMpIv\nAACRkXwBAIiMUqO9wJQpU4KxmCU4hxxySL9/syxbtiwYmzx5svn6jzzySDCWni1p4sSJ1W2Dme0F\n9cuaWaayzSq7GMyMNPWWkFS25ZWBWH2yYlZpT0dHh7ntyCOPDLa1Znb65Cc/GYwdccQRwZg0sARs\n2rRp1eXkDEdp69evLxST7HKsdDnRmjVrqsujRo0KtqtnpqRGySufK9onznwBAIiM5AsAQGQkXwAA\nIiP5AgAQGckXAIDISL4AAERG8gUAILKa6nydc9Ml/ULSbd777zjnFkiaIWld34/c6r3/ZXO6iL3J\n2LFjg7Grr77abHvTTTcFY3fccceAn61ss9qhv2aPZasm0pqeTipec5s1dZ01nV2SNUWd9V5Gjx4d\njGXV8Sa3WXW+Vs261c6qjZWkrVu39lufOnVqddmaau/9998Pxt577z1zn+vWrQvGtm3b1m89WTM8\nfvz4YDtrykXJ/oxZNd9Zv+vKtrw636JTCuYmX+dcu6Q7JP06Fbree/94ob0CiI6xDLSOWi47b5P0\nWUkr8n4QQEtjLAMtoi3vlLrCOTdf0trEparxkoZJWi1prvd+rdG8tp0AKHYNqw6DHMvq7e3dnX48\nIIBMwfFc9NnO90la573/o3PuOknzJc0t+FrYR8ybN8+MW9/dXnvttQN+9vrrr89th1x1j+WlS5f2\nW+/u7lZPT0/ujvK+G7O+t7Ri6e9fOzo6cp87XLF58+ZgbPXq1cHYypUrg7F333233/oll1yie++9\nt6b+xPjO9yMf+YjefPPN6vrrr78ebPfnP/85GHv55ZfNfVrHb8SIEdXlH/3oR7rsssuq68nnTqfN\nnDnT3GdnZ2cwNnTo0GAs/TmYPn26XnzxRUn2M6ol+/6CE088MRgrlHy998nvjBZL+l6R1wFQLsYy\nUI5CpUbOuUXOuY/2rc6W9GLDegQgGsYyUI5a7naeIelbko6QtMM5d6723DH5kHNuq6Qtkr7QzE7u\nLazb3B999NFgLOuyz1e/+lXdcsst1eUPg+OPP75w2+nTp9e0DWFlj+W88h+rrMWaai8rVimDydvn\npk2bgjHrcqNV+nTwwQeb28aMGRNse/jhhwdjVgnOgQceGIxJA49Rsg9Wf/bbL3x+li5fSktffrck\nj7V13PP2aX2G6i2Dq2wrWkqUJzf5eu+Xas//iNMWNbw3AJqGsQy0Dp5wBQBAZCRfAAAiI/kCABAZ\nyRcAgMhIvgAARFb0CVf7rI0bNwZjp59+eqF2ixZl32z6+c9/vvaOfcgdffTRNW1DuaxyDqs8R5J6\ne3sLvW56ZqLOzs7qjDp5s+BYT2FasSL8COz0rDxJWaU7yScodXR0BNtaT2Haf//wn2urJEgaePyS\n69bMTtbfLSsm2U8PO+igg/qtJ4+nNVtS3j6t2aascqysY1DpU60zZNWLM18AACIj+QIAEBnJFwCA\nyEi+AABERvIFACAyki8AAJFRalSn7373u8GYVZrw/PPPB2OhWUWOOuqo2jvWIqxykj/96U+FX/fx\nxx/vtz5jxozqthkzZhR+XdQva5aXyjarJMiacUayS0ysmW7SM/Ycc8wx1bGYNxG6NWatMiRL1jFI\nzvBjzVyUVzIUkldSlZy9afTo0f3W33rrrWC7v/71r8FY3vGxSsfS/U2uW2Vc69evN/eZLmFKam9v\nD8ayjntlBqUhQ4aY+yz6O+PMFwCAyEi+AABERvIFACAyki8AAJGRfAEAiIzkCwBAZCRfAAAio863\nTjfffHMwNmXKlGDMms7qw+SVV14Jxr7xjW+Yba1j9MUvfrGmbWhd1tR1kj0FnVXHunPnzgHbXn/9\ndUn5db5r1qwJxpK1uWnp2uKkkSNHDtiWrHm1joMVs+qgKzWpIX/5y1+qy5MmTeq3vnTp0mC75cuX\nB2NWjbRk17+mnweQXLfqfPOmFDzggAOCMet1s2qAK8fbqh2WqPMFAGCvQfIFACAyki8AAJGRfAEA\niIzkCwBAZCRfAAAiq6nUyDl3i6Suvp+/SdISSfdJGiJppaSLvffh+7g/RI4//vhg7De/+U0wdv75\n5wdjCxcuHLBt+PDh1Vvdhw8fXnsHGyQ9LVpbW1t1m1V+0NXVVXifJ598cjB26KGH1rQNtkaM5awp\n8yrbdu3aFWyXN6WgVRZklSFlTV1XKYNJTp2XxZqibsOGDcHY0KFDg7H99x/4Z/Xtt9+uLo8ePbqu\nthWrVq0KxpKvn+W5556rLs+ePVtPPvlkdX3JkiXBdpWSrSxZJV5J48aNC8bSf9OS61bpTl65mlWO\nZZWHZZUoVd6fNU1mLfGQ3DNf59ynJU333s+SdJqk/5B0o6Q7vfddkl6TdGmhvQOIhrEMtI5aLjv3\nSDqvb3mDpHZJsyUt7tv2mKTPNLxnABqNsQy0iLZ6Tpmdc/+kPZesTvXeH9q37UhJ93nv/9ZoWuy8\nHNj3tMXYySDGsnp7e3dnPREIwADB8Vzz4yWdc2dJukzSP0hKfukX5Y9FqzjllFOCMes73zPOOCMY\n+zB95ztr1qxgzHpcnySdeuqpwVjyOyoMzmDHcvpxhN3d3erp6ZFkfw9oPcoxL17Pd77f/OY39bWv\nfU1SOd/5Tpo0qd/67bffrquuuqq6Pm3atGDbo48+OhizHr9az3e+N998s6699trqehnf+SYfxfvI\nI4/o7LPPrq53dnYG2+Xd59HR0RGMWd+1p2NnnnmmFi/ec0Eo63GhSdb39NY9MDXd7eycO1XSPEn/\n6L3fKGmLc66SETol2Q/5BNASGMtAa6jlhqvRkm6V9DnvfeW/ib+SdE7f8jmSnmpO9wA0CmMZaB21\nXHY+X9I4ST9zzlW2XSLpbufc5ZLekHRvc7rXeh588MFgzLpk9NhjjwVj6ctUkrR27drq9nnz5gXb\nXn755cGYdWls5cqVwZgkLViwoN/6DTfcUJ2VaP78+WbbkLxLRj//+c8LvS5q1pCx3NY28Op01ra0\n9Ew2aVYZSVY5UUXWTDeVbXlfdbzzzjuFYlZJVdal7BdeeMGMV7z88svBmHV/jtVXSXr11Veryzff\nfLOefvrp6vrq1avNtiGHHHKIGZ88eXIwlv5bkFy3Lg/nzTBkXQK2SpiyYpVteZ9t67NgyU2+3vu7\nJN2VEfr7QnsEUArGMtA6eMIVAACRkXwBAIiM5AsAQGQkXwAAIiP5AgAQWc1PuMIe48ePD8YqM6lk\nmTt3bjB2//33Z26vPJ3nK1/5SrCtFWukG264oVpiZN16P3v27GAs9D4ryniSFxrLKuewSt+kcspE\nrLi1T2uGpqzZh5LbskqjatmnVaq1bZs9qVy6HCZZumWVAE6YMKFQTLL/Vo4dO7bfeqL0zXyilPWU\nr7y49fnLmtWoss36nUj5JXQhnPkCABAZyRcAgMhIvgAAREbyBQAgMpIvAACRkXwBAIiM5AsAQGTU\n+TaQNd3Vj3/842DszjvvzNxeqQe85557Cr3u888/H4zlufDCC4PbrrjiimC7rq6uwvvE3iFrarvK\nNqsmMm86uDFjxgRjVj1u1utWalBHjBhReJ+dnZ3BmFVXmzU14jHHHGPGK3bu3BmM1XsMktK1s93d\n3dXljo6OYLvDDjssGLPqePNet729vd/6zJkzq8vW+7SmVcxTb9thw4bV9HN5dcDBdoVaAQCAwki+\nAABERvIFACAyki8AAJGRfAEAiIzkCwBAZJQatYDQVHqV7V/60peCba1Yoz3wwAPR9oUPn7wpI8eN\nGxeMjRo1KhjLKs+ZOnWqpMGVpqSn4UuyXjdrirmzzz67urx9+/ZgW6sMySrByZoSLyl9/M4444zq\n8ujRo4PtrFKtvPKmIUOGBGPp95IsW7KOu3V88uL1HvdKH/OmpSz6GePMFwCAyEi+AABERvIFACAy\nki8AAJGRfAEAiIzkCwBAZDWVGjnnbpHU1ffzN0k6U9IMSev6fuRW7/0vm9JDAA1T5li2Sk+kgTPd\nJFklL/vvP/DP2MSJEyVJQ4cONfdpxa1Zbeopo5GkE044obqcVYo02FheOUx65h3nXHXZei/1vs+k\nesqxkv0bzPu0WG2zYoPZVy1yk69z7tOSpnvvZznnxkpaJum/JF3vvX+8qb0D0DCMZaB11HLm2yPp\nub7lDZLaJdn/hQXQihjLQIvITb7e+12SevtWL5P0hKRdkuY6566RtFrSXO/92qb1EsCgMZaB1tFW\n66OxnHNnSfpXSf8gaaakdd77PzrnrpN0uPd+rtG8+DPegH1Lc79o0qDHsnp7e3db388CqAqO51pv\nuDpV0jxJp3nvN0r6dSK8WNL3BtU9AFE0YiwvXbq033p3d7d6enoa2c0BrJtf0jdczZo1S7/73e8k\ntcYNV1OnTtXy5cur62XfcHX00UfrlVdeqa6XfcPVxz72Mb322mvV9axndVfkPdu56HOz07Guri49\n++yz5r4qrPfZ3d0djOWWGjnnRku6VdLnvPfr+7Ytcs59tO9HZkt6saZeAigNYxloHbWc+Z4vaZyk\nnyVuT79H0kPOua2Stkj6QnO6B6CBWnosW2dS1hlYuowmuS2vvCmrbS2ss9AsyZl6ip7dDmaGpnTb\nZH+s17VmGBqM9PtMnrEO5szXihd9L4M57pZabri6S9JdGaF7G98dAM3CWAZaB0+4AgAgMpIvAACR\nkXwBAIiM5AsAQGQkXwAAIiP5AgAQWU1PuAKAZqtnCrq8dpVa0bx63KJ1vvXauHFjU1+/3unvent7\nq8vNmjrP+n2mY5s3bx70a+bF663zbVZ9bwVnvgAAREbyBQAgMpIvAACRkXwBAIiM5AsAQGQkXwAA\nImtr9u3UAACgP858AQCIjOQLAEBkJF8AACIj+QIAEBnJFwCAyEi+AABEFn1WI+fcbZL+RtJuSVd7\n75fE7kOiL7MlPSzppb5N/+u9/+eS+jJd0i8k3ea9/45zbpKk+yQNkbRS0sXe+20l9meBpBmS1vX9\nyK3e+19G7M8tkrq05zN7k6QlKvf4pPtzpko8PmVgLAf7wli2+9NSYznQp6aP56jJ1zl3sqSp3vtZ\nzrmPS/qxpFkx+5DhGe/9uWV2wDnXLukOSb9ObL5R0p3e+4edc/8m6VJJ3yuxP5J0vff+8Rh9SPXn\n05Km931uxkpa1te3so5PVn/+SyUdnzIwlrMxlnP701Jj2ehT08dz7MvOfyfpUUny3r8s6WDn3KjI\nfWhF2yR9VtKKxLbZkhb3LT8m6TMl96dMPZLO61veIKld5R6frP4Mibj/VsBYzsZYtrXaWA71qenj\nOfZl5/GSlibW1/Rt2xS5H0nTnHOLJXVI+rr3/j9jd8B7v1PSTudccnN74tLLakkTSu6PJM11zl3T\n15+53vu1kfqzS1Jl9u/LJD0h6dQSj09Wf3appONTEsZyBsZybn9aaiwbfWr6eC77hqu2kve/XNLX\nJZ0l6RJJP3LODSu3S5nKPk7Snu9krvPenyLpj5Lmx+6Ac+4s7Rkcc1OhUo5Pqj+lH5+Slf0ZZSzX\nrvTPaquNZSn+eI595rtCe/53XDFRe75gL4X3/m1JD/Wt/sU5t0pSp6T/K6tPCVucc8O99+9pT59K\nvWzkvU9+Z7RYEb+TkSTn3KmS5kk6zXu/0TlX6vFJ90f9v1OLfnxKwFiuHWM5odXGclafFGE8xz7z\nfVrSuZLknDte0grv/ebIfahyzs1xzv1L3/J4SYdJerus/qT8StI5fcvnSHqqxL7IObfIOffRvtXZ\nkl6MuO/Rkm6V9Dnv/fq+zaUdn6z+lHl8SsJYrh1j+f/vu6XGcqhPMY5R9FmNnHP/Lqlb0geSrvTe\nvxC1A/37MlLSg5LGSBqmPd8TPVFCP2ZI+pakIyTt0J4/GnMkLZB0oKQ3JH3Be7+jxP7cIek6SVsl\nbenrz+pI/fkn7bns82pi8yWS7lY5xyerP/doz+Wq6MenLIzlzH4wlu3+tNRYNvrU9PHMlIIAAERW\n9g1XAADsc0i+AABERvIFACAyki8AAJGRfAEAiIzkCwBAZCRfAAAiI/kCABDZ/wOxhV4gucbBigAA\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "2sDnwM1g6deM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 2.5: Fit a logistic regression model to the approximation of the training images with 95% of explained variance. Compute the accuracy of the classifier and the time needed to train the model. Compare it to the one obtained in 2.3. What do you observe? \n"
      ]
    },
    {
      "metadata": {
        "id": "pIUyvzAS6deW",
        "colab_type": "code",
        "outputId": "6d81a55e-7986-4a5f-931b-997237c87e10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "pca95x_tr = pca25.transform(x_tr)\n",
        "pca95x_va = pca25.transform(x_va)\n",
        "\n",
        "\n",
        "tic = time()\n",
        "# Fit a linear regression model\n",
        "lr = LogisticRegression(solver='lbfgs',verbose=1,n_jobs=-1)\n",
        "lr.fit(pca95x_tr, y_tr)\n",
        "\n",
        "# Compute the classification score\n",
        "print(lr.score(pca95x_tr, y_tr))\n",
        "print(lr.score(pca95x_va, y_va))\n",
        "toc = time()\n",
        "print('The total time is %s seconds ' % (toc-tic))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.7618166666666667\n",
            "0.7632\n",
            "The total time is 4.924222469329834 seconds \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    4.7s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "9fSPR0Xx6dei",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Unsupervised learning with sklearn.cluster.KMeans()"
      ]
    },
    {
      "metadata": {
        "id": "zl-I6x0P6dej",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Exercise 3.1: Generate a set of 6 isotropic Gaussian blobs, with 1000 samples each. Each sample should have 60 features. \n",
        "\n",
        "Hint: Use the sklearn.datasets.make_blobs to generate the data"
      ]
    },
    {
      "metadata": {
        "id": "myBKJicW6del",
        "colab_type": "code",
        "outputId": "6209a3db-66b9-413a-cd69-4be556f2bec0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.datasets.samples_generator import make_blobs\n",
        "\n",
        "# Generate the data\n",
        "x, y = make_blobs(n_samples=1000, n_features=60, centers=6)\n",
        "x.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "yFcrJFxe6deu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###  Exercise 3.2: Apply PCA to the generated data. Store the first two principle components and their cluster index to a new dataframe.  Visualize the 6 blobs based only on these two components. "
      ]
    },
    {
      "metadata": {
        "id": "ZU1YxB626dev",
        "colab_type": "code",
        "outputId": "70adf013-a9c3-44a0-9dea-f8f77e0580c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "# Fit PCA to the data\n",
        "pca = PCA(n_components=2)\n",
        "pca.fit(x)\n",
        "best_comps = pca.components_\n",
        "pca2x = pca.transform(x)\n",
        "\n",
        "# Generate a new dataframe and store the first two Principle Components and the true cluster index\n",
        "df = pd.DataFrame()\n",
        "df[\"Comp_0\"] = pca2x[:,0]\n",
        "df[\"Comp_1\"] = pca2x[:,1]\n",
        "df[\"Cluster\"] = y\n",
        "df.head()\n",
        "# Vizualize the data by plotting their representation on the two Principle Components (x and y axis)\n",
        "df.plot.scatter(0,1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'c' argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with 'x' & 'y'.  Please use a 2-D array with a single row if you really want to specify the same RGB or RGBA value for all points.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe43eb9f0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEGCAYAAACHGfl5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8n3T5UA16de0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.3: Set the number of clusters to 6 and apply Kmeans clustering to the data. Compute the accuracy score between the true labels and the ones estimated by the Kmeans algorithm. "
      ]
    },
    {
      "metadata": {
        "id": "mlKOiIpo6de2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a25cf057-0e26-416e-b3fa-8c3430653629"
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Fit a Kmean model to the data\n",
        "kmeans = KMeans(n_clusters=6, random_state=0)\n",
        "kmeans.fit(x)\n",
        "\n",
        "from scipy.stats import mode\n",
        "\n",
        "# Uncomment this part to compute the accuracy score\n",
        "#  y_true: the true cluster index\n",
        "#  y_kmeans: the cluster index assigned by Kmeans\n",
        "\n",
        "y_true = df[\"Cluster\"].values\n",
        "y_kmeans = kmeans.predict(x)\n",
        "labels = np.zeros_like(y_true)\n",
        "for i in range(6):\n",
        "    mask = (y_kmeans == i)\n",
        "    labels[mask] = mode(y_true[mask])[0]\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, labels)\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "5YDsYYk26de8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Exercise 3.4: Do the same by clustering the data using only the first 2 principle components. What do you observe? "
      ]
    },
    {
      "metadata": {
        "id": "q-jEOUt86de9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e08bc3-b62b-45ed-d925-55b262d7d2d3"
      },
      "cell_type": "code",
      "source": [
        "# Solution\n",
        "\n",
        "# Fit a Kmeans model to the first 2 PCA coefficients of the data\n",
        "\n",
        "kmeans = KMeans(n_clusters=6, random_state=0)\n",
        "kmeans.fit(df[[\"Comp_0\", \"Comp_1\"]].values)\n",
        "\n",
        "# Uncomment this part to compute the accuracy score\n",
        "# y_true: the true cluster index\n",
        "# y_kmeans: the cluster index assigned by Kmeans\n",
        "\n",
        "y_true = df[\"Cluster\"].values\n",
        "y_kmeans = kmeans.predict(df[[\"Comp_0\", \"Comp_1\"]].values)\n",
        "labels = np.zeros_like(y_true)\n",
        "for i in range(6):\n",
        "    mask = (y_kmeans == i)\n",
        "    labels[mask] = mode(y_true[mask])[0]\n",
        "    \n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(y_true, labels)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.978"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "_N8hBQbrtq9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}